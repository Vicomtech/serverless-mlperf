"""
This file contains the princial class to handle the different engine_and_format
 and models workload, in Handler layers.
"""
import os
import boto3
import dldt_tools.supported_profiles as SP
import dldt_tools.json_tools as sjt

"""
This class is used in lambda_test_SUT to enable DNN inference depending on the selected DNN engine_and_format and model. 
"""


class HandlerApp:
    # it is very important to decide w
    def __init__(self, engine_and_format, exec_local=False):
        """
        :param engine_and_format: the engine_and_format defined for inference.
        :param exec_local: this flag is to test in local files.
        """
        self.exec_local = exec_local
        if not self.exec_local:
            self.local_data_path = '/tmp'
            self.s3_client = boto3.client('s3')
            self.local_models_path = self.local_data_path + '/models'
            if not os.path.exists(self.local_models_path):
                os.mkdir(self.local_models_path)
        if engine_and_format == "ocv-tf":
            from dldt_tools.tf_processor import TFProcessor
            self.net = TFProcessor()
            # self.net = opv.TFProcessor(local_models_path)
        if engine_and_format == "ie-ir":
            from dldt_tools.ov_processor import OVProcessor
            self.net = OVProcessor()
        if engine_and_format == "ocv-cf":
            from dldt_tools.caffe_processor import CaffeProcessor
            self.net = CaffeProcessor()

    def init_local(self, local_path, profile_key, make_profiling=False):
        """
        :param local_path: the local path of the models.
        :param profile_key: the profile key of the supported_profiles.py file.
        :param make_profiling: enable local profiling, for a local test.
        :return:
        """
        self.current_config = SP.PROFILES[profile_key]
        current_model_file = local_path + "/" + self.current_config["config_model_name"]
        self.net.set_config(self.current_config)
        self.net.load(current_model_file, self.current_config["inputs"], [self.current_config["outputs"]],
                      make_profiling)

    # self.network = self.net.load()
    def check_if_empty(string):
        if not string.strip():
            return True
        else:
            return False
    def init(self, key_model, subfolder_rel_path, make_profiling=False):
        """
        Initializes and loads the DNN model in AWS architecture.
        :param key_model: the supported profile key from supported_profiles.py
        :param subfolder_rel_path: the model relative path models/your_model,
         this depends on how the S3 folder structure is done.
        :param make_profiling: enable profiling for all tasks.
        :return:
        """
        self.current_config = SP.PROFILES[key_model]
        self.net.set_config(self.current_config)
        det_config_file = self.current_config["config_model_name"]
        det_model_file = self.current_config["weight_model_name"]
        local_models_path = self.local_data_path + '/models'
        if det_config_file != "mobilenet_v1_224_frozen.pbtxt":
            self.__download_file(local_models_path, det_config_file, subfolder_rel_path)
        self.__download_file(local_models_path, det_model_file, subfolder_rel_path)
        print("local_models_path {}".format(local_models_path))
        current_model_file = local_models_path + "/" + self.current_config["config_model_name"]
        print("current_model file {}".format(current_model_file))
        self.net.load(current_model_file, self.current_config["inputs"],
                      [self.current_config["outputs"]],
                      make_profiling)

    def __download_file(self, local_models_path, filename, subfolder=''):
        """
        This is a private function which downloads the files from S3 to amazon container
        :param local_models_path: the path of the downloaded model
        :param filename: the filename
        :param subfolder: the subfolder relative to the bucket.
        :return:
        """
        local_filename = local_models_path + '/' + filename
        print("downloading to {}".format(os.environ['MODELS_PATH'] + subfolder + filename
                                         ))
        if not os.path.isfile(local_filename):
            self.s3_client.download_file(os.environ['BUCKET_NAME'],
                                         os.environ['MODELS_PATH'] + subfolder +
                                         filename, local_filename)

    def init_handler_variables(self, event):

        h_var = dict()
        for record in event['Records']:
            h_var['BucketName'] = record['s3']['bucket']['name']
            h_var['ObjectKey'] = record['s3']['object']['key']
        h_var['InputFilename'] = \
            self.local_data_path + '/' + os.path.basename(h_var['ObjectKey'])
        h_var['InputData'] = sjt.read_from_s3(self.s3_client,
                                              h_var['BucketName'],
                                              h_var['ObjectKey'])
        h_var['CompletedPath'] = h_var['InputData']['CompletedPath']
        h_var['OutputPath'] = h_var['InputData']['OutputPath']
        h_var['OutputData'] = dict()
        print("this is hvar {}".format(h_var))
        print("this is inputdata->imagefilenames {}".format(h_var['InputData']['ImageFilenames']))
        h_var['ImageFilenames'] = []
        h_var['OutputPath'] = h_var['InputData']['OutputPath']
        h_var['OutputData']['ImageFilenames'] = []
        for image_key in h_var['InputData']['ImageFilenames']:
            image_filename = self.local_data_path + '/' + \
                             os.path.basename(image_key)
            print("this is the image that you are going to download {}".format(image_filename))
            self.s3_client.download_file(h_var['BucketName'], image_key,
                                         image_filename)
            h_var['ImageFilenames'].append(image_filename)
            h_var['OutputData']['ImageFilenames'].append(image_key)
            # h_var['OutputData']['ImageFilenames'].append(image_key)
        print("this is hvar {}".format(h_var))
        return h_var

    def deliver_output_data(self, h_var):
        """
        Delivers the output data to s3.
        """
        # Write and upload the output json with the results
        print("delivering the output: {}".format(h_var['OutputPath']))
        print("delivering the completed: {}".format(h_var['CompletedPath']))

        sjt.write_to_s3(h_var['OutputData'], self.s3_client,
                        h_var['BucketName'], h_var['ObjectKey'],
                        h_var['OutputPath'])

        # Move the input json to the completed folder
        sjt.write_to_s3(h_var['InputData'], self.s3_client,
                        h_var['BucketName'], h_var['ObjectKey'],
                        h_var['CompletedPath'])
        # pylint: disable=maybe-no-member
        boto3.resource('s3').Object(os.environ['BUCKET_NAME'],
                                    h_var['ObjectKey']).delete()

    def init_output_data(h_var):
        """
        TODO: this function will be removed in the next releases.
        :return:
        """
        pass

    def make_inference(self, img_path):
        """
        Make local DNN inference in the host machine.
        :param img_path: the absolute image path
        :return:
        """
        return self.net.predict(img_path, self.current_config["shape"])

    def make_aws_inference(self, h_var):
        """
        The aws inference called from lambda_test_SUT.py
        :param h_var: the previously configured variable in init_handler varaibles.
        :return:
        """
        h_var['OutputData']['inf_perf'] = []
        for image_filename in h_var['ImageFilenames']:
            result = self.net.predict(image_filename, self.current_config["shape"])
            h_var['OutputData']['inf_perf'].append(self.net.get_profiling())
            h_var['OutputData']['result'] = result

    def make_mlperf_inference(self, feed, input, size):
        """
        Optional function, makes the inference from an array of data, (no images).
        :param feed: the array of floating data
        :param input: the input index name of the data
        :param size: the size of the image_array
        :return:
        """
        return self.net.predict_mlperf(feed, input, size)

    def get_profiling(self):
        """
        gets the profiling data if enable_profiling option is activated in the class.
        :return:
        """
        return self.net.get_profiling()
