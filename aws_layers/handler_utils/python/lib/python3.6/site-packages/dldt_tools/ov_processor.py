import cv2
import os
import numpy as np
import datetime
import time
import dldt_tools.backend


class OVProcessor(dldt_tools.backend.Backend):
    def __init__(self):
        super(OVProcessor, self).__init__()
        self.inputs = []
        self.outputs = []
        self.net = None
        self.image_src = None
        self.profiling_information = {}

    def version(self):
        """
             gets inference version of the selected framework.
        """
        return "no version defined:"

    def name(self):
        """
           prints the backend name
        """
        return "OpenCV dldt"

    def image_format(self):
        """
           prints image format
         """
        return "NCHW"
    def set_config(self, config):
        """
          sets the configuration of the model, depending on the supported profiles.
          :param config:
          :return:
        """
        self.config = config

    def load(self, model_path, inputs=None, outputs=None, make_profiling=False):
        """
            loads the DNN model into the backend inference
            :param model_path: the model path to load the model
            :param inputs: the input layer name of the DNN model
            :param outputs: the output layer name of the DNN model
            :param make_profiling: for enabling profiling
            :return:
       """
        self.make_profiling = make_profiling
        self.inputs = inputs
        self.outputs = outputs
        if model_path.endswith(".xml"):
            print("the extension of the file is correct.")
            raw_model = model_path.split(".")
            config_model = model_path
            weight_model = raw_model[0] + ".bin"
            print("config {}".format(config_model))
            print("weight {}".format(weight_model))
            if os.path.exists(config_model) and \
                    os.path.exists(weight_model):
                print("starting_loading the model")
                try:
                    if self.make_profiling:
                        t0 = time.time()
                    self.net = cv2.dnn.readNetFromModelOptimizer(config_model, weight_model)
                    self.net.setPreferableBackend(cv2.dnn.DNN_BACKEND_INFERENCE_ENGINE)
                    if self.make_profiling:
                        t1 = time.time()
                        performance_in_ms = 1e3 * (t1 - t0)
                        self.profiling_information["load_model"] = performance_in_ms
                except:
                    raise Exception("something weird happen with loading the model")
            else:
                raise Exception("the {} and {} file does not exist".format(config_model, weight_model))
        else:
            raise FileNotFoundError("File not found please provide .xml file")
        return self

    def get_profiling(self):
        """
             gets the profiling results
        """
        if self.make_profiling == False:
            print("The profiling is not configured, please activate profiling in the load function parameter.")
            print("-------------Profile----------------------")
            print("Note: time performances are in ms")
        return self.profiling_information

    def load_input(self, image, input_shape):
        """
            Loads the dataset image provided from OSS (Amazon S3).
        """
        if self.image_src is None:
            if os.path.isfile(image):
                pass
            else:
                raise FileNotFoundError("the image is not found")
        if self.make_profiling:
            t0 = time.time()
        self.image_src = cv2.imread(image)
        input_image = self.resize_input(self.image_src, input_shape)
        if len(self.config["mean"]) > 0:
            mean = self.config["mean"]
            self.blob = cv2.dnn.blobFromImage(input_image, size=(input_shape[2], input_shape[3]),
                                              mean=(mean[0],
                                                    mean[1],
                                                    mean[2]), swapRB=True)
        else:
            self.blob = cv2.dnn.blobFromImage(input_image, size=(input_shape[2], input_shape[3]), swapRB=False)
        if self.make_profiling:
            t1 = time.time()
            performance_in_ms = 1e3 * (t1 - t0)
            self.profiling_information["image_operations"] = performance_in_ms
        return self.blob

    # this is only for prediction of local testing
    def predict(self, feed, shape):
        """
             makes the prediciton of the DNN inference
        """
        blob = self.load_input(feed, shape)
        self.net.setInput(blob)
        if self.make_profiling:
            t0 = time.time()
        outs = self.net.forward(self.outputs[0])
        if self.make_profiling:
            t1 = time.time()
            performance_in_ms = 1e3 * (t1 - t0)
            self.profiling_information["forward"] = performance_in_ms
        #     self.__det_net.setInput(blob)
        return outs
    # this is only for local testing when you are loading an image
    def resize_input(self, frame, target_shape):
        """
            Resizes the input data to the target shape
         """
        return cv2.resize(frame, (target_shape[3], target_shape[2]))

    # this is for mlperf remote and local testing
    def predict_mlperf(self, feed, input, size):
         """
            (optional) makes the prediciton of the DNN inference with profiling stats
           :param size: size of the floating data array.
           :param input: input info about DNN
           :param feed: the array floating point data .
           :return:
         """
         feed_length = len(feed[input])
         result_list = []
         for i in range(0, feed_length):
            input_shape = None
            if self.make_profiling:
                t0 = time.time()
            self.prepare_Input(feed, i, input, size)
            if self.make_profiling:
                t1 = time.time()
                performance_in_ms = 1e3 * (t1 - t0)
                self.profiling_information["preparing input"] = performance_in_ms
                t0 = time.time()
            outs = self.net.forward(self.outputs[0])
            if self.make_profiling:
                t1 = time.time()
                performance_in_ms = 1e3 * (t1 - t0)
                self.profiling_information["forward_mlperf"] = performance_in_ms
            result_list.append(outs[0].tolist())
         return result_list

    def prepare_Input(self, feed, i, input, size):
        """
           private function nto prepare the input DNN blob
        """
        input_shape = np.array(feed[input][i]).reshape(1, size[1], size[2], size[3])
        input_shape = input_shape.astype(np.uint8)
        self.net.setInput(input_shape, input)

# if __name__ == '__main__':
#     main()
def chooseFramework(framework, cv_type):
    """
    for local test
    :param framework:
    :param cv_type:
    :return:
    """
    if cv_type == "classification":
        models_path = "mobilenetv1/FP32/"
        if framework == "openvino":
            backend = "mobilenet-ov-runtime"
        elif framework == "tensorflow":
            backend = "mobilenet-tf-runtime"
        elif framework == "caffe":
            backend = "mobilenet-caffe-runtime"
    if cv_type == "object_detection":
        models_path = "ssd-mobilenetv1/FP32/"
        if framework == "openvino":
            backend = "ssd-mobilenet-ov-runtime"
        elif framework == "tensorflow":
            backend = "ssd-mobilenet-tf-runtime"
        elif framework == "caffe":
            backend = "ssd-mobilenet-caffe-runtime"
    backend_handler = HandlerApp(framework)
    backend_handler.init(backend, models_path, make_profiling = True)
    return backend_handler